У цьому параграфі ми стисло пройдемося по двом алгоритмам оптимізації які є попередниками методу множників які змінюють напрямок. Цей матеріал не використовується у подальшому, але складає підґрунтя до наступних розділів і вмотивовує спосіб їх викладення.

\subsection{Метод двоїстого сходження}

Розглянемо задачу опуклої оптимізації з обмеженням типу рівність:

\begin{equation}
	\label{eq:2.1}	
	f(x) \xrightarrow[A x = b]{} \min,
\end{equation}

де змінна $x \in \RR^n$, (стала) матриця $A \in \RR^{m \times n}$, (сталий) вектор $b \in \RR^m$, і функція $f: \RR^n \to \RR$ є опуклою. \medskip

Функцією Лагранжа задачі \eqref{eq:2.1} є

\begin{equation}
	L(x, y) = f(x) + y^\intercal \cdot (A x - b),
\end{equation}

а двоїстою функцією

\begin{equation}
	g(y) = \Inf_x L(x, y) = - f^* \left( - A^\intercal y \right) - b^\intercal \cdot y,
\end{equation}

де $y$ є двоїстою змінною, або множником Лагранжа, а $f^*$ позначає опукле спряження функції $f$; див.~\cite[\S3.3]{20} або \cite[\S12]{140} для визначення. Двоїста задача має вигляд

\begin{equation}
	g(y) \to \max,
\end{equation}

де змінна $y \in \RR^m$. У припущенні строгої двоїстості, оптимальні значення прямої і двоїстої задач однакові. \medskip0

Ми можемо відновити оптимальну точку $x^*$ прямої задачі з двоїстої оптимальної точки $y^*$ наступним чином:

\begin{equation}
	x^* = \Argmin_x L(x, y^*),
\end{equation}

якщо існує тільки одне\footnote{Ця остання умова часто виконується, зокрема її виконання забезпечує строга опуклість $f$.} значення $x$ яке мінімізує $L(x, y^*)$. 

\begin{definition}
    У подальшому ми будемо використовувати запис $\argmin_x F(x)$ на позначення \textit{довільного} значення $x$ що мінімізує $F(x)$, навіть якщо воно не єдине.
\end{definition}

У методі двоїстого сходження, ми розв'язуємо двоїсту задачу використовуючи градієнтне сходження.

\begin{remark}
    У припущення диференційовності $g$, градієнт $\nabla g(y)$ може бути знайденим наступним чином. Спершу ми знаходимо $x^+ = \argmin_x L(x,y)$; тоді маємо $\nabla g(y) = Ax^+ - b$, тобто нев'язка умови рівності.
\end{remark}

Таким чином, метод двоїстого сходження складається з ітеративних оновлень:

\begin{align}
	\label{eq:2.2}
	x^{k + 1} &\coloneqq \Argmin_x L \left( x, y^k \right), \\
	\label{eq:2.3}
	y^{k + 1} &\coloneqq y^k + \alpha^k \cdot \left( A x^{k + 1} - b \right),
\end{align}

де $\alpha^k > 0$ --- розмір кроку, а верхній індекс позначає номер ітерації. Перший крок \eqref{eq:2.2} є кроком мінімізації по змінній $x$, а другий крок \eqref{eq:2.3} є оновленням двоїстої змінної. 

\begin{definition}
    Двоїсту змінну $y$ можна інтерпретувати як вектор цін нев'язок по компонентам, тому крок її оновлення ще називаються \textit{оновленням цін}, або \textit{підбором цін}. 
\end{definition}

Цей алгоритм називається двоїстим сходження бо при правильному виборі $\alpha^k$ двоїста функція зростає на кожному кроці, тобто $g(y^{k + 1}) > g(y^k)$. \medskip

Метод двоїстого сходження може бути застосованим навіть у деяких випадках\footnote{У цьому випадку алгоритм зазвичай називають двоїстим субградієнтним методом \cite{152}.} коли $g$ не є диференційовною. Тоді нев'язка $Ax^k - b$ буде не градієнтом $g$, але мінус \textit{субградієнтом} $-g$. Цей випадок потребує іншого вибору $\alpha^k$ і, взагалі кажучи, не гарантує монотонну збіжність, тобто зачасту $g(y^{k + 1}) \not> g (y^k)$. \medskip

Якщо ж обирати $\alpha^k$ правильним чином, і виконуються ще кілька інших припущень, то $x^k$ збігається до оптимальної точки, а $y^k$ збігається до оптимальної точки двоїстої задачі. Однак, ці припущення часто не виконуються у багатьох застосування, тому двоїсте сходження не може бути застосованим у таких випадках. 

\begin{example}
    Якщо $f$ є відмінною від нуля афінною функцією довільної компоненти $x$ то крок \eqref{eq:2.2} виконати неможливо, оскільки $L$ є необмеженою знизу по $x$ для більшості $y$. 
\end{example}

\subsection{Метод двоїстої декомпозиції}

Однією з головних переваг метод двоїстого сходження є те, що у деяких випадках він призводить до децентралізованого алгоритму. 

\begin{assumption}
    Припустимо, для прикладу, що цільова функція $f$ є \textit{розділимою} (відносно розбиття змінної на під-вектори), тобто що
    
    \begin{equation}
    	f(x) = \Sum_{i=1}^N f_i(x_i),
    \end{equation}
    
    де $x = (x_1, \ldots, x_N)$ і змінні $x_i \in \RR^{n_i}$ є під-векторами $x$.
\end{assumption}

Розбиваючи $A$ відповідним чином:

\begin{equation}
	A = [A_1 \cdots A_N],
\end{equation}

отримаємо $Ax = \sum_{i=1}^N A_i x_i$, а тому функція Лагранжа може бути записана у вигляді

\begin{equation}
	L(x, y) = \Sum_{i = 1}^N L_i(x_i, y) = 
	\Sum_{i = 1}^N \left( f_i(x_i) + y^\intercal A_i x_i - (1 / N) y^\intercal b \right),
\end{equation}

тобто також є розділимою по $x$. Це означає, що крок \eqref{eq:2.2} мінімізації по $x$ розбивається на $N$ незалежних задач які можуть бути розв'язані паралельно. А саме, алгоритм набуває вигляд

\begin{align}
	\label{eq:2.4}
	x_i^{k + 1} &\coloneqq \Argmin_{x_i} L_i \left( x_i, y^k \right), \\
	\label{eq:2.5}
	y^{k + 1} &\coloneqq y^k + \alpha^k \cdot \left( A x^{k + 1} - b \right),
\end{align}

Крок \eqref{eq:2.4} мінімізації по $x$ виконуються незалежно, паралельно для всіх $i = 1, \ldots, N$.

\begin{definition}
    У цьому випадку ми називаємо метод двоїстого сходження методом \textit{двоїстої декомпозиції}.
\end{definition}

У загальному випадку кожна ітерація методу двоїстої декомпозиції вимагає виконання операцій \textit{трансляції} та \textit{збору}. У кроці \eqref{eq:2.5} оновлення двоїсто змінної для обчислення нев'язки збираються ``внески'' $a_i x_i^{k + 1}$ всіх під-векторів. Після оновлення двоїстої змінної її нове значення транслюється до $N$ процесів для виконання $N$ незалежних кроків \eqref{eq:2.4} мінімізації по $x_i$. \medskip

Двоїста декомпозиція є давньою ``ідеологією'' в оптимізації, і її використання відстежується принаймні до ранніх 1960-их. Схожі ідеї зустрічаються у відомих роботах Данціга і Вольфа \cite{44} та \cite{13} щодо великомасштабних задач лінійного програмування, а також у (seminal) книзі Данціга \cite{43}. Схоже, що загальна ідея двоїстої декомпозиції належить Еверету \cite{69}, але досліджується у і багатьох більш ранніх роботах \cite{107, 84, 117, 14}. Використання недиференційовної оптимізації, таке як субградієнтний метод, для розв'язання двоїстої задачу обговорюється Шором у \cite{152}. Гарні матеріали стосовно двоїстих методів і декомпозиції включаються також книгу Берцекаса \cite[глава 6]{16} і огляд Недіча і Оздаглара \cite{131} розподіленої оптимізації, який обговорює двоїсту декомпозицію і задачі (consensus). Багато статей також досліджують варіації стандартної двоїстої декомпозиції, як-то \cite{129}. \medskip

Взагалі кажучи, децентралізована оптимізація була активною галуззю для досліджень з початку 1980-их. Наприклад, Цицикліс та його співавтори працювали над багатьма децентралізованими задачами (detection and consensus) що включали мінімізацію гладкої функції $f$ відомої багатьом агентам \cite{160, 161, 17}. Деякі гарні матеріали щодо паралельної оптимізації включають роботи \cite{17} Берцекаса і Цицикліса, та \cite{31} Цензора і Зеніоса. Нещодавно також проводилася робота над задачами, де у кожного агента є своя власна опукла (але можливо не диференційовна) цільова функція \cite{130}. У \cite{54} можна знайти свіже обговорення розподілених методів для (graph-structured) задач оптимізації.

\subsection{Доповнена функція Лагранжа і метод множників}

Методи що використовують доповнені функції Лагранжа були розроблені щоб привнести стійкість у метод двоїстого сходження і гарантувати збіжність без таких обмежень як строга опуклість чи скінченність $f$. 

\begin{definition}
    \textit{Доповненою функцією Лагранжа} задачі \eqref{eq:2.1} називається

    \begin{equation}
    	\label{eq:2.6}
    	L_\rho (x, y) = 
    	f(x) + y^\intercal \cdot (A x - b) + (\rho / 2) \cdot \|A x - b\|_2^2,
    \end{equation}
    
    де $\rho > 0$ називається\footnote{Зауважимо, що $L_0$ є стандартною функцією Лагранжа цієї задачі.} \textit{штрафним параметром}.
\end{definition}

Доповнену функцію Лагранжа можна розглядати як стандартну функцію Лагранжа задачі

\begin{equation}
	f(x) + (\rho / 2) \cdot \| A x - b\|_2^2 \xrightarrow[A x = b]{} \min.
\end{equation}

Ця задача, очевидно, еквівалентні початковій задачі \eqref{eq:2.1}, оскільки для довільного допустимого $x$ до цільової функції додається доданок що дорівнює нулеві. Відповідною доповненою двоїстою функцією є $g_\rho = \inf_x L_\rho(x, y)$. \medskip

Перевагою додавання штрафного доданку є те, що $g_\rho$ стає диференційовною за більш слабких умов на оригінальну задачу. Градієнт доповненої двоїстої функції знаходиться так само як для звичайної функції Лагранжа. \medskip

Застосування двоїстого сходження до модифікованої задачі приводить до алгоритму

\begin{align}
	\label{eq:2.7}
	x^{k + 1} &\coloneqq \Argmin_x L_\rho \left( x, y^k \right), \\
	\label{eq:2.8}
	y^{k + 1} &\coloneqq y^k + \rho \cdot \left( A x^{k + 1} - b \right),
\end{align}

також відомому як \textit{метод множників} для задачі \eqref{eq:2.1}. \medskip

Це все той же метод двоїстого сходження, хіба що у кроці мінімізації по $x$ використана доповнена функція Лагранжа, а розмір кроку $\alpha^k$ взятий штрафним параметром $\rho$. 

\begin{remark}
    Метод множників збігається за набагато більш загальних умов ніж метод двоїстого сходження, включаючи випадки коли $f$ набуває значення $+\infty$ або не є строго опуклою.
\end{remark}

\begin{proposition}
    Вибір розміру кроку у \eqref{eq:2.8} рівним $\rho$ легко поясними.
\end{proposition}

\begin{assumption}
    Для простоти припустимо, що $f$ диференційовна (хоча цього і не вимагається для роботи алгоритму). 
\end{assumption}

\begin{proof}
    Тоді умовами оптимальності для задачі \eqref{eq:2.1} є пряма і двоїста допустимість, тобто
    
    \begin{equation}
    	A x^* - b = 0, \quad \nabla f(x^*) + A^\intercal y^* = 0,
    \end{equation}
    
    відповідно. \medskip
    
    За визначенням, $x^{k + 1}$ мінімізує $L_\rho(x, y^k)$, тому
    
    \begin{align}
    	0 &= \nabla_x L_\rho \left(x^{k + 1}, y^k\right) = \\
    	  &= \nabla_x f \left(x^{k + 1}\right) + 
    	  A^\intercal \cdot \left(y^k + \rho \cdot \left(A x^{k + 1} - b\right)\right) = \\
    	  &= \nabla_x f \left(x^{k + 1}\right) + A^\intercal \cdot y^{k + 1}.
    \end{align}
    
    Як бачимо, при використанні $\rho$ у якості розміру кроку у оновленні двоїстої змінної, ітерації $\left( x^{k + 1}, y^{k + 1} \right)$ є двоїсто допустимою.
\end{proof}

Тому, коли при ітераціях методу множників нев'язка $A x^{k + 1} - b$ прямує до нуля, то цього достатньо для оптимальності. \medskip

Значно покращена збіжність методу множників приходить не безкоштовно. А саме, коли $f$ є розділимою, доповнена функція Лагранжа вже не є розділимою, тому крок \eqref{eq:2.7} мінімізації по $x$ не може бути виконаний паралельно\footnote{Це означає, що базовий варіант методу множників не може бути використаний для декомпозиції. Ми розглянемо цю проблему далі.} для кожного $x_i$.  \medskip

Доповнені функції Лагранжа і метод множників для оптимізації з обмеженнями були вперше запропоновані у пізніх 1960-их Хестенесом у \cite{97, 98} і Пауеллом \cite{138}. Багато з перших чисельних експериментів над методом множників належать Міле і ко. \cite{124, 125, 126}. Більшість ранніх праць зібрані у монографії Берцекаса \cite{15}, який також обговорює схожість з більш давніми методами що використовували функції Лагранжа і штрафні функції \cite{6, 5, 71}, а також багато узагальнень.