% cls && pdflatex lab-1-report.tex && cls && pdflatex lab-1-report.tex && start lab-1-report.pdf
\input{lab.sty}

\begin{document}

\cover{1}{Методи розв'язування нелінійних рівнянь}

\section{Постановка задачі} 

Нехай маємо рівняння $f(x) = 0$, $\bar x$ -- його розв'язок, тобто $f(\bar x)=0$. Процес розв'язування цього рівняння розбивається на етапи: 
\begin{enumerate}
\item Перевірка існування та визначення кількості коренів.
\item Відділення коренів, тобто розбиття $\RR$ на інтервали, на кожному з яких рівно один корінь.
\item Обчислення на кожному з цих інтервалів кореня із заданою точністю  $\epsilon$
\end{enumerate}

Будемо вважати, що ставиться задача, у якій у заданої функції $f$ на заданому проміжку $[a, b]$ є рівно один корінь.\\

Мета лабораторної роботи: реалізувати пункт 3 трьома різними методами, проаналізувати кожен із них, і зробити відповідні висновки.\\

Були використані методи простої ітерації, січних, та хорд для знаходження найменшого за модулем додатного кореня рівняння $x^4 - 4 x^3 + 5.5 x^2 - 3x + 0.5 = 0$ з точністю $\epsilon = 10^{-6}$.

\section{Теоретична частина} 

\subsection{Метод простої ітерації}

Метод полягає у заміні рівняння $f(x) = 0$ еквівалентним йому рівнянням $x = \phi(x)$. Далі запускається ітераційний процес вигляду $x_{n + 1} = \phi(x_n)$, де початкове наближення $x_0$ задається. \\

Для збіжності методу важливо правильно перейти до функції $\phi$, простим вибором є $\phi(x) = x + f(x)$, а більш розумним -- $\phi(x) = x + \tau(x) \cdot f(x)$, де $\tau(x)$ -- знакостала на $[a, b]$ функція така, що виконуються достатні умова збіжності, тобто $\Max_{x\in[a,b]} |\phi^\prime(x)| \le q < 1$ і $m = |x_1 - x_0| \le \delta (1 - q)$, де $\delta = \Max_{x\in[a,b]}|x - x_0|$. \\

\textit{Переваги} методу: простота, при $q < 1 / 2$ метод збігається швидше ніж метод ділення навпіл, метод узагальнюється на системи.\\

\textit{Недоліки} методу: при $q > 1 / 2$ збігається повільніше ніж метод ділення навпіл, виникають складнощі при зведенні $f(x) = 0$ до $\phi(x) = x$.

\subsection{Модифікований метод Ньютона}
Модифікований метод Ньютона полягає у проведенні наступного ітераційного процесу: $x_{n+1} = x_n - f(x_n) / f^\prime(x_0)$, де $x_0$ -- задане. Враховуючи, що модифікований метод Ньютона є просто частинним випадком методу простої ітерації (і методу релаксації), то для збіжності достатньо $\Max_{x\in[a,b]} |\phi^\prime(x)| \le q < 1$.\\

\textit{Переваги} методу: немає необхідності обчислювати похідну на кожній ітерації.\\

\textit{Недоліки} методу: має лише лінійну збіжність, тобто $|x_{n+1} - \bar x| = O(|x_k - \bar x|)$.

\subsection{Метод січних}

Метод полягає у проведенні ітераційного процесу $x_{n+1} = x_n - \dfrac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})} \cdot f(x_n)$, де $x_0$, $x_1$ -- задані.\\

\textit{Переваги} методу: степінь збіжності $\phi = \left(1 + \sqrt 5\right) /2$, узагальнюється на системи і рівняння в $\CC$.\\

\textit{Недоліки} методу: збіжність методу залежить від початкового наближення $x_0$, і необхідно $f\in C^{(2)}([a,b])$.


\section{Практична частина}

Попередній графічний аналіз показує, що найменший за модулем додатній корінь приблизно дорівнює 0.29, тому шукатимемо корінь на проміжку $[a, b] = [0, 0.4]$.

\subsection{Метод простої ітерації}
Візьмемо $\tau(x) = 0.6$, тоді $\phi^\prime(x) = x + 0.6 \cdot (x^4 - 4 x^3 + 5.5 x^2 - 3x + 0.5)$. \\

Покажемо, що $\phi$ опукла на $[0, 0.4]$, тоді її максимум на одному з країв інтервалу. \\

Справді, $\phi^{\prime\prime}(x) = 6.6 - 14.4 x + 7.2 x^2$, її корені $x_{1,2} = 1 \pm \sqrt{1/3} / 2$, $x_{1, 2} > 1 / 2 > 0.4$. \\

Далі підставляємо краї: $|\phi^\prime(0)| = |-0.8| = 0.8$, $|\phi^\prime(0.4)| = 0.8416 \Rightarrow q = \Max_{x\in[a,b]} |\phi^\prime(x)| = 0.8416 < 1$, отже метод гарантовано зійдеться. \\

Візьмемо $x_0 = \dfrac{a + b}{2} = 0.2$. \\

Знайдемо $m = |x_1 - x_0| = 168/3125 = 0.05376 \le 0.16832 = \delta (1 - q)$, де $\delta = \Max_{x\in[a,b]}|x - x_0| = 0.2$. \\

Таким чином метод гарантовано зійдеться. \\

Кількість ітерацій $n \ge \left[ \dfrac{\ln \left(\dfrac{\epsilon(1-q)}{(b-a)}\right)}{\ln q} \right] + 1 > 86$. \\

Справді, метод успішно відпрацьовує, причому за значно меншу кількість ітерацій:
    
\begin{table}[H]
    \centering
    \begin{tabular}{|r|l|l|l|}
        \hline
        $n$ & $x_n$ & $f(x_n)$ & $|x_n - x_{n-1}|$ \\ \hline
        1 & 0.2 & 0.0896 & 0.2 \\
        2 & 0.25376 & 0.0316717363 & 0.05376 \\
        3 & 0.2727630418 & 0.0152704811 & 0.019003 \\
        4 & 0.2819253304 & 0.0080599509 & 0.0091623 \\
        5 & 0.286761301 & 0.0044305753 & 0.004836 \\
        6 & 0.2894196461 & 0.0024864697 & 0.0026583 \\
        7 & 0.290911528 & 0.0014111068 & 0.0014919 \\
        8 & 0.2917581921 & 0.00080581 & 0.0008467 \\
        9 & 0.292241678 & 0.0004617709 & 0.0004835 \\
        10 & 0.2925187406 & 0.0002651468 & 0.0002771 \\
        11 & 0.2926778287 & 0.0001524198 & 0.0001591 \\
        12 & 0.2927692806 & 0.000087676 & 9.15e-05 \\
        13 & 0.2928218862 & 0.0000504525 & 5.26e-05 \\
        14 & 0.2928521577 & 0.0000290388 & 3.03e-05 \\
        15 & 0.292869581 & 0.0000167159 & 1.74e-05 \\
        16 & 0.2928796105 & 0.000009623 & 1e-05 \\
        17 & 0.2928853843 & 0.00000554 & 5.8e-06 \\
        18 & 0.2928887083 & 0.0000031895 & 3.3e-06 \\
        19 & 0.292890622 & 0.0000018363 & 1.9e-06 \\
        20 & 0.2928917237 & 0.0000010572 & 1.1e-06 \\
        21 & 0.292892358 & 0.0000006087 & 6e-07 * \\ \hline
    \end{tabular}
\end{table}

\subsection{Модифікований метод Ньютона}

Будемо шукати корінь на $[0.2, 0.3]$. \\

Перевіримо збіжність звичайного методу Ньютона: \\

Знайдемо $x_0$ для якого $f^{\prime\prime}(x_0)\cdot f(x_0) > 0$: \\

$f^{\prime\prime}(x) = 11 - 24 x + 12 x^2 > 0$ на $[0, 0.4]$, тому достатньо просто вибрати $x_0$ так, що $f(x_0) > 0$, наприклад $x_0 = 0.2$ для якого $f(x_0) = 0.0896 > 0$, тоді $|x_0 - \bar x| \le 0.1$. \\

\[ m_1 = \min_{x \in [a, b]} f^\prime(x) \qquad M_2 = \max_{x \in [a, b]} f^{\prime\prime}(x). \]

Умова збіжності $q = \dfrac{M_2}{2m_1} |x_0 - \bar x| \le 1$:

\begin{equation*}
    \left\{
        \begin{aligned}
            f^\prime(0.2) &= -1.248 \\
            f^\prime(0.3) &= -0.672
        \end{aligned}
    \right.
    \Rightarrow m_1 = 0.672
\end{equation*}

\begin{equation*}
    \left\{
        \begin{aligned}
            f^{\prime\prime}(0.2) &= 6.68 \\
            f^{\prime\prime}(0.3) &= 4.88
        \end{aligned}
    \right.
    \Rightarrow M_2 = 6.68
\end{equation*}

$q \le \dfrac{6.68}{1.344} \cdot 0.1 \approx 0.497 < 1$, отже метод гарантовано зійдеться. \\

Кількість ітерацій $n \ge \left[ \dfrac{\ln \left(\dfrac{|x_0 - \bar x|}{\epsilon}\right)}{\ln (1/q)} \right] + 1 > 17$. \\

Але це оцінка на кількість ітерацій методу Ньютона а не модифікованого, тому може бути більше ітерацій. \\

Справді, метод успішно відпрацьовує:
\begin{table}[H]
    \centering
    \begin{tabular}{|r|l|l|l|}
        \hline
        $n$ & $x_n$ & $f(x_n)$ & $|x_n-x_{n-1}|$ \\ \hline
         1 & 0.2          & 0.0896       & 0.2 \\
        2 & 0.2444444444 & 0.0404538333 & 0.0444444 \\
        3 & 0.26451083   & 0.0221485969 & 0.0200664 \\
        4 & 0.2754972372 & 0.0130723485 & 0.0109864 \\
        5 & 0.281981537  & 0.008017075  & 0.0064843 \\
        6 & 0.2859582608 & 0.0050249356 & 0.0039767 \\
        7 & 0.2884507884 & 0.003190859  & 0.0024925 \\
        8 & 0.2900335557 & 0.0020425975 & 0.0015828 \\
        9 & 0.291046749  & 0.0013141928 & 0.0010132 \\
        10 & 0.2916986303 & 0.0008482741 & 0.0006519 \\
        11 & 0.2921194012 & 0.00054867   & 0.0004208 \\
        12 & 0.2923915589 & 0.0003553566 & 0.0002722 \\
        13 & 0.2925678271 & 0.0002303515 & 0.0001763 \\
        14 & 0.2926820887 & 0.000149403  & 0.0001143 \\
        15 & 0.2927561974 & 0.0000969357 & 7.41e-05 \\
        16 & 0.2928042806 & 0.0000629086 & 4.81e-05 \\
        17 & 0.2928354852 & 0.0000408321 & 3.12e-05 \\
        18 & 0.2928557393 & 0.0000265056 & 2.03e-05 \\
        19 & 0.2928688869 & 0.0000172068 & 1.31e-05 \\
        20 & 0.292877422  & 0.0000111707 & 8.5e-06 \\
        21 & 0.292882963  & 0.0000072522 & 5.5e-06 \\
        22 & 0.2928865603 & 0.0000047084 & 3.6e-06 \\
        23 & 0.2928888958 & 0.0000030569 & 2.3e-06 \\
        24 & 0.2928904121 & 0.0000019846 & 1.5e-06 \\
        25 & 0.2928913966 & 0.0000012885 & 1e-06 * \\ \hline
    \end{tabular}
\end{table}

\subsection{Метод січних}

Почнемо з $x_0 = 0.05$, $x_1 = 0.1$. Апріорних умов збіжності немає, тому просто перевіримо чи метод зійдеться перевіряючи на кожній ітерації умови $|x_n - x_{n-1}| < \epsilon$ та $|f(x_n)| < \epsilon$.
\begin{table}[H]
    \centering
    \begin{tabular}{|r|l|l|l|}
        \hline
        $n$ & $x_n$ & $f(x_n)$ & $x_n - x_{n-1}$ \\ \hline
        1 & 0.1          & 0.2511       & 0.05           \\
        2 & 0.2119420451 & 0.0751672237 & 0.1119420451   \\
        3 & 0.2597692489 & 0.026269176  & 0.0478272038   \\
        4 & 0.2854631426 & 0.0053930356 & 0.0256938937   \\
        5 & 0.292100772  & 0.0005619159 & 0.0066376294   \\
        6 & 0.2928728061 & 0.000014435  & 0.0007720341   \\
        7 & 0.2928931617 & 0.0000000404 & 0.0000203556   \\
        8 & 0.2928932188 & 0.0000000000 & 0.0000000571 * \\ \hline
    \end{tabular}
\end{table}

\section{Висновки}

Як бачимо, ми або заощаджуємо на аналізі (дослідженні) функції але виграємо у простоті методу, або ж заощаджуємо на кількості ітерацій/швидкодії, але додатково аналізуємо функцію (обчислюємо похідні, скінченні різниці, тощо).

\end{document}
